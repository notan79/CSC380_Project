{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0666946a",
   "metadata": {},
   "source": [
    "- - - - - - - - - - - - - - - - - - -\n",
    "# 1. Imports\n",
    "## Relevent Modules - purpose:\n",
    "    - Pandas     - dataframe, data representation\n",
    "    - Numpy      - data manipulation, random generation\n",
    "    - Sklearn    - Regression models, data split, one-hot encoding, \n",
    "                   metrics, cross validation\n",
    "    - Matplotlib - Data visualization\n",
    "    - Seaborn    - Data visualization\n",
    "    - Random     - Shuffling data\n",
    "\n",
    "## Module Versions:\n",
    "    - Pandas:     '1.5.3'\n",
    "    - Numpy:      '1.24.3'\n",
    "    - Sklearn:    '1.3.0'\n",
    "    - Matplotlib: '3.7.1'\n",
    "    - Seaborn:    '0.12.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4fa37a",
   "metadata": {},
   "source": [
    "- - - - - - - - - - - - - - - - - - -\n",
    "# 2. Data\n",
    " - Reads in the data from a cleaned file\n",
    " - Removes null lines and corrects empty class for 'fel_misd'\n",
    " - Normalizes the relevent columns\n",
    " - Remove the oversized and generate data for undersized classes:\n",
    "     - M: 46803 $\\to$ 2194\n",
    "     - F: 16407 $\\to$ 2194\n",
    "     - C: 2194  $\\to$ 2194\n",
    "     - S: 240   $\\to$  360\n",
    "     - P: 50    $\\to$   75\n",
    "     \n",
    "     - Note that the data generation is done using the distribution\n",
    "       of each of the inputs per each class. Since the inputs have\n",
    "       low correleation (see the correlation heatmap) the joint pdf\n",
    "       will be extremely close to the individual pdf for each input.\n",
    " - One hot encode the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc292f1a",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.1 Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./clean_data/fully_merged_data.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete empty values\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null values\n",
    "arr = df.index[df[\"fel_misd\"] == ' ']\n",
    "df = df.drop(arr, axis=0)\n",
    "arr = df.index[df[\"fel_misd\"] == '\\xa0']\n",
    "df = df.drop(arr, axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fde93a",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2 Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10866368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score normalize desired columns\n",
    "from scipy.stats import zscore\n",
    "\n",
    "need_norm = [\"age\",\"MEDHINC_CY\", \"WLTHINDXCY\", \"TOTHH_CY\"]\n",
    "norm = df[need_norm].apply(zscore)\n",
    "norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27409b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[need_norm] = norm\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794c8f7",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3 Over and under-sized classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8117a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fel_misd\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6642e",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3.1 Drop random points from oversized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_arr = df.index[df[\"fel_misd\"] == 'M'].tolist()\n",
    "shuffle(m_arr)\n",
    "\n",
    "\n",
    "df = df.drop(m_arr[0:len(m_arr)-2194], axis = 0)\n",
    "\n",
    "\n",
    "s_arr = df.index[df[\"fel_misd\"] == 'S'].tolist()\n",
    "p_arr = df.index[df[\"fel_misd\"] == 'P'].tolist()\n",
    "\n",
    "f_arr = df.index[df[\"fel_misd\"] == 'F'].tolist()\n",
    "shuffle(f_arr)\n",
    "df = df.drop(f_arr[0:len(f_arr)-2194], axis = 0)\n",
    "\n",
    "df['fel_misd'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7ac65",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3.2 Statistical Generation for Undersized Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_df(temp_df,samples=1):\n",
    "    ''' \n",
    "    Assume that temp_df is only populated with same fel_misd class and no one-hot \n",
    "    encoding\n",
    "    Age, MEDHINC_CY, WLTHINDXCY, time_arr, TOTHH_CY should be normalized prior\n",
    "    to calling this function \n",
    "    '''\n",
    "\n",
    "    # Dictionary to put into data frame\n",
    "    d = {}\n",
    "    \n",
    "    # Find the pdf for the 'sex' input\n",
    "    choices = temp_df['sex'].value_counts().index.to_list()\n",
    "    v_c = temp_df['sex'].value_counts()\n",
    "    probs = v_c/sum(v_c)\n",
    "    \n",
    "    # Update the dictionary at 'sex' to data generated from pdf\n",
    "    d['sex'] = np.random.choice(choices, p=probs, size=samples)\n",
    "    \n",
    "    # Repeat...\n",
    "    choices = temp_df['day'].value_counts().index.to_list()\n",
    "    v_c = temp_df['day'].value_counts()\n",
    "    probs = v_c/sum(v_c)    \n",
    "    d['day'] = np.random.choice(choices, p=probs,size=samples)\n",
    "    \n",
    "    choices = temp_df['month'].value_counts().index.to_list()\n",
    "    v_c = temp_df['month'].value_counts()\n",
    "    probs = v_c/sum(v_c)    \n",
    "    d['month'] = np.random.choice(choices, p=probs, size=samples)\n",
    "    \n",
    "    x = np.random.normal(0,1,size=(5,samples))\n",
    "    d['age'] = x[0]\n",
    "    d['MEDHINC_CY'] = x[1]\n",
    "    d['WLTHINDXCY'] = x[2]\n",
    "    d['time_arr'] = x[3]\n",
    "    d['TOTHH_CY'] = x[4]\n",
    "    d['fel_misd'] = [temp_df['fel_misd'].to_list()[0] for i in range(samples)]\n",
    "    \n",
    "    df_return = pd.DataFrame.from_dict(d)\n",
    "\n",
    "    \n",
    "    return df_return\n",
    "\n",
    "# Increase the undersized class by 50%\n",
    "s_amt = (int) (0.5*240)  \n",
    "p_amt = (int) (0.5*50)    \n",
    "inp = df[df['fel_misd'] == 'S']\n",
    "s_temp = gen_rand_df(inp,s_amt)\n",
    "\n",
    "inp = df[df['fel_misd'] == 'P']\n",
    "p_temp = gen_rand_df(inp,p_amt)\n",
    "\n",
    "df = pd.concat([df,s_temp,p_temp])\n",
    "df['fel_misd'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d04227",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.4 One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_encoded = pd.get_dummies(df, columns=['sex', 'day', 'month'], drop_first=True)\n",
    "df_pandas_encoded = df_pandas_encoded.drop(\"WLTHINDXCY\", axis=1)\n",
    "df_pandas_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b3927c",
   "metadata": {},
   "source": [
    "- - - - - - - - - - - - - - - - - - -\n",
    "# 3. Pre-Training\n",
    "- Find the train and test sets (0.8 train split)\n",
    "- Find all the combinations of the inputs\n",
    "- Perform 5-fold cross validation for each combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ace448",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.1 Find the Input and Output names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = list(df_pandas_encoded.columns)\n",
    "oup = [\"fel_misd\"]\n",
    "for x in oup:\n",
    "    inp.remove(x)\n",
    "inp, oup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3cb75",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = df_pandas_encoded[inp], df_pandas_encoded[oup]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9093fb3",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Find Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83dfa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "items = ['MEDHINC_CY','age','sex_M', 'day', 'month']\n",
    "combs = []\n",
    "for i in range(1, len(items)):\n",
    "    combs.append(list(set(itertools.combinations(items, i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a908adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_vals = ['day_1',\n",
    "          'day_2',\n",
    "          'day_3',\n",
    "          'day_4',\n",
    "          'day_5',\n",
    "          'day_6']\n",
    "\n",
    "month_vals = ['month_1',\n",
    "              'month_2',\n",
    "              'month_3',\n",
    "              'month_4',\n",
    "              'month_5',\n",
    "              'month_6',\n",
    "              'month_7',\n",
    "              'month_8',\n",
    "              'month_9',\n",
    "              'month_10',\n",
    "              'month_11']\n",
    "\n",
    "best_dict = {\"features\": [], \"score\": -2**31}\n",
    "for k_amt in combs:\n",
    "    for ind_comb in k_amt:\n",
    "        comb = list(ind_comb)\n",
    "        if 'day' in comb:\n",
    "            comb.remove('day')\n",
    "            comb += day_vals\n",
    "        if 'month' in comb:\n",
    "            comb.remove('month')\n",
    "            comb += month_vals\n",
    "\n",
    "        \n",
    "        x_subset = x_train[comb].values\n",
    "        cvs = cross_val_score(linear_model.LogisticRegression(multi_class='ovr'), x_subset, y_train)\n",
    "        \n",
    "        if cvs.mean() > best_dict[\"score\"]:\n",
    "            best_dict[\"features\"] = comb\n",
    "            best_dict[\"score\"] = cvs.mean()\n",
    "best_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791284b7",
   "metadata": {},
   "source": [
    "-------\n",
    "# 4. Training Logistic Model\n",
    "- Train a 5-class logistic regression using one-vs-rest classification\n",
    "    - Use the best features calculated in cross validation\n",
    "- Fit the train data\n",
    "- Find the predicted data for the test set and show the accuracy\n",
    "- Visualize and show the confusion matrix using heatmap\n",
    "- Show the classification report\n",
    "- Show the weights for each input and model\n",
    "    - Both tabular and heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a083725",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb748acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_r = linear_model.LogisticRegression(penalty='l2', multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeac175",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dict[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aaea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[best_dict[\"features\"]]\n",
    "x_test = x_test[best_dict[\"features\"]]\n",
    "\n",
    "log_r.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c1fcbc",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.2 Analysis\n",
    "---\n",
    "### 4.2.1 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17438081",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_r.predict(x_test)\n",
    "print(f\"Accuracy train: {log_r.score(x_train,y_train)}\")\n",
    "print(f\"Accuracy Test: {log_r.score(x_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da591921",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.2.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91840c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.arange(0.5,5,1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sb.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xticks(temp, labels=log_r.classes_)\n",
    "plt.yticks(temp, labels=log_r.classes_)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73cb536",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.2.3 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49cc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e9a92",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.2.4 Coefficient Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f244b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(log_r.coef_, columns=log_r.feature_names_in_)\n",
    "df = df.set_index(log_r.classes_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(df.T, annot=True, cmap='Blues')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Input')\n",
    "plt.title(\"Heatmap of Coefficients for Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f5b3e",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Pre-Training\n",
    "- Find the train and test sets (0.8 train split)\n",
    "- Find all the combinations of the inputs\n",
    "- Perform 5-fold cross validation for each combination\n",
    "---\n",
    "## 5.1 Find the Input and Output  Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f50daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = list(df_pandas_encoded.columns)\n",
    "oup = [\"MEDHINC_CY\"]\n",
    "for x in oup:\n",
    "    inp.remove(x)\n",
    "inp.remove('fel_misd')\n",
    "inp, oup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c306bf0d",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.2 Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9589e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = df_pandas_encoded[inp], df_pandas_encoded[oup]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5c104",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.3 Find Combinations\n",
    "---\n",
    "### 5.3.1 5-Fold CV for Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['age','sex_M', 'day', 'month']\n",
    "combs = []\n",
    "for i in range(1, len(items)):\n",
    "    combs.append(list(set(itertools.combinations(items, i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85139c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_vals = ['day_1',\n",
    "          'day_2',\n",
    "          'day_3',\n",
    "          'day_4',\n",
    "          'day_5',\n",
    "          'day_6']\n",
    "\n",
    "month_vals = ['month_1',\n",
    "              'month_2',\n",
    "              'month_3',\n",
    "              'month_4',\n",
    "              'month_5',\n",
    "              'month_6',\n",
    "              'month_7',\n",
    "              'month_8',\n",
    "              'month_9',\n",
    "              'month_10',\n",
    "              'month_11']\n",
    "\n",
    "best_dict = {\"features\": [], \"score\": -2**31, \"alpha\": 0}\n",
    "alpha_vals = np.logspace(-1,3,50)\n",
    "for k_amt in combs:\n",
    "    for ind_comb in k_amt:\n",
    "        comb = list(ind_comb)\n",
    "        if 'day' in comb:\n",
    "            comb.remove('day')\n",
    "            comb += day_vals\n",
    "        if 'month' in comb:\n",
    "            comb.remove('month')\n",
    "            comb += month_vals\n",
    "\n",
    "        \n",
    "        x_subset = x_train[comb].values\n",
    "        \n",
    "        for alpha in alpha_vals:\n",
    "            cvs = cross_val_score(linear_model.Ridge(alpha=alpha), x_subset, y_train)\n",
    "        \n",
    "        if cvs.mean() > best_dict[\"score\"]:\n",
    "            best_dict[\"features\"] = comb\n",
    "            best_dict[\"score\"] = cvs.mean()\n",
    "best_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b549f98",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.3.2 20-Fold CV for Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.LassoLarsCV(cv=20)\n",
    "lasso.fit(x_train, y_train)\n",
    "lasso_mse=lasso.mse_path_\n",
    "lasso_alphas = lasso.cv_alphas_\n",
    "mse_mean = []\n",
    "mse_std = []\n",
    "for i in range(len(lasso_mse)):\n",
    "    mse_mean.append(lasso_mse[i].mean())\n",
    "    mse_std.append(lasso_mse[i].std())\n",
    "    \n",
    "min_alpha = lasso_alphas[np.argmin(mse_mean)]\n",
    "print(f\"Best Average MSE: {min(mse_mean)} with {min_alpha=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(lasso_alphas,mse_mean, yerr=mse_std,fmt=\"o\", capsize=5, color=\"blue\")\n",
    "plt.scatter(lasso_alphas, mse_mean, color='blue')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.axvline(x=min_alpha, color='red')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean MSE')\n",
    "plt.title('Alpha vs Mean MSE');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71b1a8",
   "metadata": {},
   "source": [
    "-----\n",
    "# 6. Training Regression Models\n",
    "- Find the input variables wanted\n",
    "- Split the data\n",
    "- Find all the possible combinations of inputs\n",
    "- Use cross validation for multiple alpha values for a Ridge model\n",
    "- Use cross validation on the Lasso model\n",
    "- Visualize the Lasso alphas\n",
    "- Fit the Ridge regression (Linear regression since $\\alpha=0$\n",
    "- Show the relevent information\n",
    "    - $R^2$ \n",
    "    - Residual plot\n",
    "- Fit the Lasso regression with the best $\\alpha$\n",
    "- Show the relevent information\n",
    "    - $R^2$ \n",
    "    - Residual plot\n",
    "- Show the weights for each input and model\n",
    "    - Both tabular and heatmap\n",
    "\n",
    "---\n",
    "## 6.1 Training Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d861fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge alpha is 0, use linear regression: https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Ridge.html\n",
    "# Lasso alpha is 0.0067 try lasso\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "x_train = x_train[best_dict[\"features\"]]\n",
    "x_test = x_test[best_dict[\"features\"]]\n",
    "\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b780f",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.2 Analysis\n",
    "---\n",
    "### 6.2.1 Coefficient of Determination: $R^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)\n",
    "print(f\"R2 train: {lr.score(x_train,y_train)}\")\n",
    "print(f\"R2 Test: {lr.score(x_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949c8fc",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.2.2 Residual Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a197ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([i for i in range(len(y_test))],y_test-y_pred);\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_actual-y_predicted\")\n",
    "plt.title(\"Residual Plot\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9868ad6",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.3 Training Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lasso = linear_model.Lasso(alpha=min_alpha)\n",
    "lr_lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678f0cb",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.4 Analysis\n",
    "---\n",
    "### 6.4.1 Coefficient of Determination: $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0466b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lasso_pred = lr_lasso.predict(x_test)\n",
    "print(f\"R2 train: {lr_lasso.score(x_train,y_train)}\")\n",
    "print(f\"R2 Test: {lr_lasso.score(x_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5130400",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.4.2 Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([i for i in range(len(y_test))],y_test.values.reshape(-1)-y_lasso_pred);\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_actual-y_predicted\")\n",
    "plt.title(\"Residual Plot\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1787ea",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.5 Coefficient Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here\n",
    "df1 = pd.DataFrame(lr.coef_, columns=lr.feature_names_in_)\n",
    "df2 = pd.DataFrame(lr_lasso.coef_.reshape(1,-1), columns=lr_lasso.feature_names_in_)\n",
    "df = pd.concat([df1,df2])\n",
    "df[\"Name\"] = [\"Linear Regression\", \"Lasso\"]\n",
    "df = df.set_index(df[\"Name\"])\n",
    "df = df.drop(\"Name\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e226ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(df.T, annot=True, cmap='Blues')\n",
    "plt.xlabel('Type of Model')\n",
    "plt.ylabel('Input')\n",
    "plt.title(\"Heatmap of Coefficients for Inputs per Model\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
